{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice vosk faster-whisper soundfile\n",
    "!apt-get install -y portaudio19-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from IPython.display import Audio\n",
    "\n",
    "tts = gTTS(\"Hello, this is a test audio for speech to text models.\", lang=\"en\")\n",
    "tts.save(\"test_audio.mp3\")\n",
    "\n",
    "Audio(\"test_audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d94234",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i test_audio.mp3 -ar 16000 -ac 1 test.wav -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
    "!unzip -q vosk-model-small-en-us-0.15.zip\n",
    "\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import wave, json\n",
    "\n",
    "wf = wave.open(\"test.wav\", \"rb\")\n",
    "rec = KaldiRecognizer(Model(\"vosk-model-small-en-us-0.15\"), 16000)\n",
    "\n",
    "result = \"\"\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if not data:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        result += json.loads(rec.Result())[\"text\"] + \" \"\n",
    "\n",
    "result += json.loads(rec.FinalResult())[\"text\"]\n",
    "print(\"VOSK:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q faster-whisper\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = WhisperModel(\"small\", device=device)\n",
    "\n",
    "segments, info = model.transcribe(\"test.wav\")\n",
    "text = \" \".join([s.text for s in segments])\n",
    "\n",
    "print(\"WHISPER:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14b805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
